\def\para#1{%
  \medskip\penalty-250%
  \setbox0=\hbox{\bf#1}\dimen0=\parindent\advance\dimen0 by -\wd0%
  \noindent\box0\hskip\dimen0}
\def\A{\para{A:}}
\def\Q{\para{Q:}}
\def\limp{\Rightarrow}

\Q Can we use FreeBoogie instead of Boogie already?

\A No. There are unfortunately many wrinkles that need to be straightened.
A particularly annoying one is that the implementation of loop cutting has
a soundness bug. A complete list of known issues appears on FreeBoogie's
site at Google Code. So far, the development of FreeBoogie happened in
coding sprints. There was one in 2007, one in 2008, and one in 2009, each
about six weeks in length. The one for 2010 is overdue. It {\it must\/}
happen before Christmas, preferably earlier.

\Q What is the main contribution of your PhD?

\Q What is the main {\it theoretical\/} contribution of your PhD?

\Q Does FreeBoogie handle loops?

\A [Note: Don't forget to compare with symbolic execution and abstract
interpretation.] [Note: Explain how cutting {\it should\/} be done.]

\Q Did you describe FreeBoogie's design in a peer-reviewed paper?

\Q Should verification condition generators use weakest precondition or
strongest postcondition?

\A [Note: Mention the triggers gotcha.]

\Q The comparison between different types of semantics is pretty standard,
isn't it?

\Q You present a proof technique for showing the correctness of algorithms
that simplify verification conditions. What exactly are the properties an
algorithm needs in order to be able to apply this proof technique?

\Q Does FreeBoogie handle Boogie's polymorphic types?

\Q Isn't it cheating to assume that loops have been dealt with when you
address code reachability?

\Q Your reachability analysis identifies four very different types of
problems.  Are these problems distinguished in error messages? If no, then
how can it be done?

\Q The example you give in the introduction is quite algorithmic in nature.
Why do you think this is the kind of problems that ``program verifiers
ought to be able'' to handle ``in the future''?

\Q You suggest that the front-end of program verifiers is uninteresting.
Why?

\Q You say that `insights' lead to simpler and more efficient
implementations.  Which insight leads to which efficiency gain? Which
insight leads to which simplification?

\Q What does `structural' mean in `structural operational semantics'?
(Does it describe `operational semantics' or does it restrict to a kind?)

\Q Why do you say that denotational semantics are not much used today?

\Q What is a Kripke structure?

\Q Which SMT solver did you use?

\Q How does Boogie compare to Why?

\Q How does ACSL compare to JML?

\Q There is a standard command language for SMT provers. Why do you say
this is prover dependent?

\Q Who uses FreeBoogie? What are the future plans for it?

\Q How big is the codebase of FreeBoogie?

\Q What {\it are\/} the differences between symbolic execution and abstract
interpretation?

\Q How come Kleene's algorithm for building regular expressions out of
automata and Gauss's algorithm for solving systems of linear equations are
$kij$ algorithms?

\Q You say that ``fortunately, the dissertation does not stem from one big
contribution, but rather from many smaller ones that are related.'' I would
say this is {\it unfortunate}, because any set of articles with unimportant
contributions from some area of research can be described in the same way.
So, how is your thesis different from a set of unimportant articles glued
together, which are `related' only because they fit roughly the same
research area?

\Q What are the important design decisions and how did they affect
FreeBoogie?

\Q On what kind of formulas does {\it prune\/} work well?

\Q Why develop FreeBoogie when the Boogie tool from MSR is open source?

\Q Is parallel assignment in core Boogie? The grammar in Figure~2.2 says
``no,'' the typing rule in Figure~2.5 says ``yes.''

\A Parallel assignment is not handles by the semantics explicitly. The
typing rule is too optimistic.

\Q You say that ``Boogie does not facilitate reasoning about termination.''
What kind of features would make it easy to reason about termination?

\Q You say that FreeBoogie adds prover-dependent axioms. Does it use
multiple provers? Can you give an example of an axiom that is sent in one
way to one prover and another way to another prover?

\Q Does FreeBoogie handle triggers? Aren't the benchmarks for wp/sp
meaningless in the absence of triggers?

\Q The `unsharing' algorithm seems to be a very heavyweight solution to a
problem that has a simple engineering solution: communicate with the prover
using its API. How do you comment?

\Q Chapter~3 is very different from the others and makes the dissertation
heterogeneous. Is there any reason it should stay?

\Q Aren't there too many jokes?

\Q Is AstGen a contribution of you thesis? It seems that you simply
describe in too much detail some engineering effort.

\A [Note: Mention research on similar tools. Yes, it is a contribution, but
not central.]

\Q Why did you waste time developing AstGen instead of using some existing
infrastructure for developing compilers?

\Q You describe a very general type of visitors, which makes the
description hard to follow. Moreover, you only use `normal' visitors, so
the general description is not needed. Why did you do it?

\Q Is there anything novel about the way you use visitors?

\Q What is the difference between an interpretation of a formula and a
model of a formula?

\Q How does FreeBoogie's prover interface compare to that of Why?

\Q You say that Benton's technique of doing equivalence proofs fits well
with the Boogie language. Can you elaborate?

\Q Why does FreeBoogie not support the SMT language?

\A [When the backend was developed, there was no SMT command language.]

\Q How many users does FreeBoogie have? If none, then why?

\Q Why isn't reachability analysis implemented in FreeBoogie?

\Q There is one chapter about incremental verification and one chapter
about semantic reachability analysis. None is implemented in FreeBoogie. It
seems that the theoretical work is not sufficiently backed by experimental
evidence.  How do you comment?

\Q Can you characterize the programs for which the weakest precondition is
superpolynomial? What about the strongest postcondition?

\Q Can you shorten the background on computational complexity?

\A [I'd rather have {\it more\/} background in the other chapters.]

\Q Why is a passive form of~$G$ equivalent to~$G$? (Page~52 states that ``it
is easy to see''.)

\Q You say that $16\%$~of Boogie benchmarks use {\bf goto} in an
interesting way. Can you give an example?

\Q Why do you introduce the notion of {\it non-redundant\/} passive
form?

\A [See Theorem 2 and Conjecture 1.]

\Q Did you make any progress on the open problems related to passivation?
Is anyone else interested in these problems?

\Q The thesis seems more concerned with solving cute toy problems, rather
than solving real problems. Isn't this a waste of energy?

\Q How do {\it passive forms\/} relate to {\it dynamic single assignment\/}?

\Q Can you describe, briefly, how matching algorithms work?

\Q Why is the weakest precondition method complete? And the strongest
postcondition method?

\Q On page~72 you derive the strongest postcondition of {\bf assert}~$q$.
The precondition is~$a$, and every OK postcondition~$b$ must make $a\limp
(q\land b)$ valid. There is no solution unless $|a\limp q|$.  When there
are solutions, the strongest one is $a$, which is equivalent to~$a\land q$.
Why do you use the latter, more complicated expression in~(5.14)?

\A [Fewer cases in~(5.21).]

\Q Can you explain why $(v\gets q)\;p\not\equiv(v=q)\limp p$?

\Q Can you prove that $$|(v\gets q)\;p|=|(v\limp q)\limp p|$$ when $p$~is
monotonic in~$v$?

\Q You argue that ${\it vc}_{\rm sp}$ is ``especially amenable'' to
splitting because it is a big conjunction. However, this seems like a
superficial advantage, because the conjoined parts do have lots of shared
subparts.  Is there any merit in your appreciation?

\Q Why do you spell out simple proofs in so much detail?

\Q The whole thesis describes a purely engineering effort to improve an
existing program. Moreover, in many cases the engineering effort is merely
planed, rather than carried out. What makes you think this work is worthy
of a PhD?

\Q In Section~6.3 you say that SMT solvers search for a `store', but, as
far as I know, SMT solvers are not familiar with the concept of a `store'.
Can you explain what you meant?

\Q How would a {\it prune\/} predicate look like in order to take advantage
of the VC shapes generated by the weakest precondition method?

\Q It is unclear what is the problem addressed in Section~6.4. What is the
point of getting rid of decorated names if the decoration is needed?

\A [Well, the decoration is not strictly speaking needed. It is just a
convenient way to explain (and implement) how the answer of the prover is
interpreted. In a way, we maintain that convenience, without sacrificing
speed.]

\Q The `proof technique' of Chapter~6 is straightforward. Why is it
presented as an important contribution of the dissertation?

\A [The first thing you'd try is different. Maybe the `proof technique' is
obvious only with hindsight?]

\Q Could you clarify what is the idea of `edit\&verify' and what is
implemented? Could you clarify what you hope may be achieved by
implementing the idea fully? Why did you not do so?

\Q You say that prunning is not worthwhile for easy queries. But how do you
know which queries are easy?

\A [(1)~You remember previous response times. (2)~I hope it's good on
average.]

\Q Is efficiency a primary goal of FreeBoogie or not? On one hand you choose
to typecheck the Boogie AST several time, on the other you run after small
improvements in speed in several chapters.

\A [It is, but it comes after correctness. The idea is to keep its code
as obviously correct as possible, by doing plenty of sanity checks, by
splitting tasks into very small subtasks, by tackling incrementality in
{\it one\/} place only, etc.]

\Q How does your work on edit\&verify compare with the work of Beckert and
Klebanov?

\Q Is edit\&verify useless if identifiers aren't decorated (say, because of
an expressive SMT command language)?

\Q The experiments were done using several tools---Spec$^\sharp$, ESC/Java,
FreeBoogie, Fx7, Simplify. Is there any place in the dissertation that
describes the relations between these? Is there a reason you didn't stick
to one or two tools?

\Q In Figure~7.7 you give a flowgraph in which all non-initial nodes are
direct children of the initial node. If the postcondition of the initial
node is satisfiable, then all nodes are semantically reachable. Therefore,
one prover query is enough to establish that we are indeed in the common
case with no bugs. However, the algorithm in Figure~7.9, despite being
designed to be fast in the common case with no bugs, will make one query
for each non-initial node. What is the problem?

\A [We also want to detect doomed code.]

\Q What kind of doomed assertions did you find in JavaFE (see page~120)?

\Q It is bothersome that 1-out-of-5 warnings given by reachability analysis
have no known cause. What makes you confident that the problem isn't
reachability analysis itself?

\Q Why not use abstract interpretation or symbolic execution to detect
semantically unreachable code?

\A [Separation of concerns: loops first, then other problems. Since loops
are such a central problem, I'm not really convinced that such separation
of concerns is a good idea, but I've inherited it from ESC/Java. I do plan
to do semantic reachability analysis in jStar.]

\Q What exactly is the relation between {\it unreachable code\/} and {\it
doomed code\/} on one hand and Lermer's {\it dead paths\/} and {\it dead
commands\/} on the other hand?

\Q What do you mean by ``well-founded specification'' (see page~121)?

\bye
% vim:textwidth=75:
